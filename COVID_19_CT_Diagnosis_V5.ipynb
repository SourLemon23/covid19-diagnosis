{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "COVID-19 CT Diagnosis V5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SourLemon23/covid19-diagnosis/blob/master/COVID_19_CT_Diagnosis_V5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgT4IENiWErj"
      },
      "source": [
        "# # Grad-CAM\n",
        "# ! pip install keras==2.2.0\n",
        "# ! pip install tensorflow==1.10.0\n",
        "# ! pip install keras==2.2.2 # EfficientNet PyPi\n",
        "# ! pip install tensorflow==1.12.0 # EfficientNet PyPi\n",
        "\n",
        "# Versions that are compatible with vis\n",
        "# ! pip install keras==2.2.4\n",
        "# ! pip install tensorflow==1.14.0\n",
        "# ! pip install keras_applications >= 1.0.7\n",
        "# https://stackoverflow.com/questions/57773636/no-attribute-set-keras-submodules\n",
        "\n",
        "# ! pip install vis\n",
        "# ! pip install scipy==1.1.0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjjOAtntgVOi",
        "outputId": "a9ac3ad0-e6c2-4eb8-f555-5d1867ef68ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import datetime\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass\n",
        "\n",
        "print('Using TensorFlow Version:', tf.__version__)\n",
        "\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, TensorBoard\n",
        "\n",
        "# # Clear any logs from previous runs\n",
        "# rm -rf ./logs/\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# EfficientNetB7\n",
        "! pip install -U efficientnet\n",
        "from efficientnet.tfkeras import EfficientNetB7\n",
        "# from keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "import scipy\n",
        "print('Using SciPy Version:', scipy.__version__) # Should be 1.1.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow Version: 2.3.0\n",
            "Collecting efficientnet\n",
            "  Downloading https://files.pythonhosted.org/packages/53/97/84f88e581d6ac86dcf1ab347c497c4c568c38784e3a2bd659b96912ab793/efficientnet-1.1.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.5)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n",
            "Using SciPy Version: 1.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zYrjoRnc2dc",
        "outputId": "367e8c8f-7af6-49a8-e17c-67ffc805d4cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Make sure hardware accelerator is set to \"GPU\"\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6kecoNB96D_",
        "outputId": "e1584dd1-d033-4829-ba4c-19d18a2b93c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Authorize access to mount Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqhZS-bor5Kj"
      },
      "source": [
        "# Initialize dataset directories (Google Drive)\n",
        "ct_training_dir   = r'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_ct_dataset V4/Training'\n",
        "ct_validation_dir = r'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_ct_dataset V4/Validation'\n",
        "ct_testing_dir    = r'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_ct_dataset V4/Testing'\n",
        "\n",
        "# Saved Weights\n",
        "checkpoint_filepath = 'covid19_ct_model.h5'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVdTndo2sEa_"
      },
      "source": [
        "# Initialize constants\n",
        "\n",
        "# Make constants all CAPS\n",
        "classes = ['COVID-19 Positive', 'COVID-19 Negative']\n",
        "# img_width, img_height = 150, 150\n",
        "img_width, img_height = 224, 224\n",
        "target_size = (img_width, img_height)\n",
        "input_shape = (img_width, img_height, 3)\n",
        "\n",
        "testing_set_start_index = -50\n",
        "testing_set_end_index = 49\n",
        "\n",
        "batch_size = 30\n",
        "epochs = 10\n",
        "dropout_rate = 0.2\n",
        "metrics = ['accuracy',\n",
        "           Precision(name='precision'),\n",
        "           Recall(name='recall')]\n",
        "\n",
        "COVID_THRESHOLD = 0.3\n",
        "EQUIDDST_MEAS = 0.5\n",
        "NORMAL_THRESHOLD = 0.7\n",
        "\n",
        "PERCENTAGE_FACTOR = 100;"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R7YBkHyiXiC"
      },
      "source": [
        "# From https://github.com/haydengunraj/COVIDNet-CT/blob/8599c2a87856326a18bbdf6ffa5987f9c1e64b4b/data_utils.py#L40\n",
        "def body_contour(binary_image):\n",
        "    \"\"\"Helper function to get body contour\"\"\"\n",
        "    contours = find_contours(binary_image)\n",
        "    areas = [cv2.contourArea(cnt) for cnt in contours]\n",
        "    body_idx = np.argmax(areas)\n",
        "    return contours[body_idx]\n",
        "\n",
        "\n",
        "def auto_body_crop(image, scale=1.0):\n",
        "    \"\"\"Roughly crop an image to the body region\"\"\"\n",
        "    # Create initial binary image\n",
        "    filt_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "    thresh = cv2.threshold(filt_image[filt_image > 0], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[0]\n",
        "    bin_image = np.uint8(filt_image > thresh)\n",
        "    erode_kernel = np.ones((7, 7), dtype=np.uint8)\n",
        "    bin_image = cv2.erode(bin_image, erode_kernel)\n",
        "\n",
        "    # Find body contour\n",
        "    body_cont = body_contour(bin_image).squeeze()\n",
        "\n",
        "    # Get bbox\n",
        "    xmin = body_cont[:, 0].min()\n",
        "    xmax = body_cont[:, 0].max() + 1\n",
        "    ymin = body_cont[:, 1].min()\n",
        "    ymax = body_cont[:, 1].max() + 1\n",
        "\n",
        "    # Scale to final bbox\n",
        "    if scale > 0 and scale != 1.0:\n",
        "        center = ((xmax + xmin)/2, (ymin + ymax)/2)\n",
        "        width = scale*(xmax - xmin + 1)\n",
        "        height = scale*(ymax - ymin + 1)\n",
        "        xmin = int(center[0] - width/2)\n",
        "        xmax = int(center[0] + width/2)\n",
        "        ymin = int(center[1] - height/2)\n",
        "        ymax = int(center[1] + height/2)\n",
        "\n",
        "    return image[ymin:ymax, xmin:xmax], (xmin, ymin, xmax, ymax)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJKmCSqIqFDe"
      },
      "source": [
        "# Augment data\n",
        "# MAKE COMMENTS ON RIGHT OF EACH AUGMENTATION!!!!!!!!!!!!!\n",
        "training_data_gen = ImageDataGenerator(rescale=1./255,\n",
        "                                       featurewise_center=False, # Set input mean to 0 over dataset\n",
        "                                       samplewise_center=False, # Set each sample mean to 0\n",
        "                                       featurewise_std_normalization=False, # Divide inputs by std of dataset\n",
        "                                       samplewise_std_normalization=False, # Divide each input by its std\n",
        "                                       horizontal_flip=True,\n",
        "                                       vertical_flip=True,\n",
        "                                       zoom_range=0.15,\n",
        "                                       shear_range=0.15,\n",
        "                                       rotation_range=360,\n",
        "                                       width_shift_range=0.15,\n",
        "                                       height_shift_range=0.15,\n",
        "                                       validation_split=0.15)\n",
        "\n",
        "validation_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "testing_data_gen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yL5qRmWqJ_t"
      },
      "source": [
        "# Split data\n",
        "training_generator = training_data_gen.flow_from_directory(ct_training_dir,\n",
        "                                                           target_size=target_size,\n",
        "                                                           class_mode='binary',\n",
        "                                                           batch_size=batch_size,\n",
        "                                                           shuffle=True)\n",
        "\n",
        "#  SHUFFLE = TRUE??\n",
        "validation_generator = validation_data_gen.flow_from_directory(ct_validation_dir,\n",
        "                                                               target_size=target_size,\n",
        "                                                               class_mode='binary',\n",
        "                                                               batch_size=batch_size,\n",
        "                                                               shuffle=False)\n",
        "\n",
        "testing_generator = testing_data_gen.flow_from_directory(ct_testing_dir,\n",
        "                                                         target_size = target_size,\n",
        "                                                         class_mode='binary',\n",
        "                                                         batch_size=batch_size,\n",
        "                                                         shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Koy33zgrnfHR"
      },
      "source": [
        "# base_model = EfficientNetB7(weights='imagenet',\n",
        "#                             include_top=True)\n",
        "\n",
        "# base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Z219vZcemI"
      },
      "source": [
        "# Create a neural network\n",
        "def create_model():\n",
        "    # Instantiate a base model with pre-trained weights\n",
        "    base_model = EfficientNetB7(weights='imagenet',\n",
        "                                include_top=False,\n",
        "                                input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "\n",
        "    # Add new classifier layers to end of base_model\n",
        "    x = BatchNormalization()(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # x = Dropout(0.3)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(2560, activation=\"relu\")(x)\n",
        "    x = Dense(2560, activation=\"relu\")(x)\n",
        "\n",
        "    # A Dense classifier with a single unit (binary classification)\n",
        "    predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    # Freeze the base model\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = Model(inputs=base_model.inputs, outputs=predictions)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAjH_v2nrX-d"
      },
      "source": [
        "# Print a summary of the network architecture\n",
        "def print_model_summary(model):\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq1iB5fEraE-"
      },
      "source": [
        "# Configure model\n",
        "def compile_model(model):\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam', # tf.keras.optimizers.RMSprop(lr=1e-4)\n",
        "                  metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sCAg3T0jewd"
      },
      "source": [
        "# def exponential_decay(lr0, s):\n",
        "#         def exponential_decay_fn(epoch):\n",
        "#             return lr0 * 0.1 **(epoch / s)\n",
        "#     return exponential_decay_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjaNqpx9rdcb"
      },
      "source": [
        "# Train the model\n",
        "def fit_model(model):\n",
        "    # Early Stopping Implementation from: https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_03_4_early_stop.ipynb\n",
        "    # Early Stopping Documentation: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
        "    # es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "    #                                           min_delta=1e-3,\n",
        "    #                                           patience=3,\n",
        "    #                                           verbose=1,\n",
        "    #                                           mode='auto')\n",
        "\n",
        "    checkpoint_cb = ModelCheckpoint(checkpoint_filepath,\n",
        "                                    save_best_only=True)\n",
        "\n",
        "    early_stopping_cb = EarlyStopping(patience=3,\n",
        "                                      restore_best_weights=True)\n",
        "\n",
        "    # exponential_decay_fn = exponential_decay(0.01, 20)\n",
        "\n",
        "    # lr_scheduler = LearningRateScheduler(exponential_decay_fn)\n",
        "\n",
        "    # https://www.tensorflow.org/tensorboard/get_started\n",
        "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_cb = TensorBoard(log_dir=log_dir,\n",
        "                                 histogram_freq=1)\n",
        "\n",
        "    history = model.fit(training_generator,\n",
        "                        epochs=epochs,\n",
        "                        steps_per_epoch=(training_generator.n/batch_size),\n",
        "                        validation_data=validation_generator,\n",
        "                        validation_steps=(validation_generator.n/batch_size),\n",
        "                        callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])\n",
        "    \n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    \n",
        "    %tensorboard --logdir logs/fit\n",
        "    \n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhAtKxg8rfqI"
      },
      "source": [
        "# Visualize metrics with graphs\n",
        "def evaluate_model(history):\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
        "    ax = ax.ravel()\n",
        "\n",
        "    for i, metric in enumerate(['accuracy', 'loss', 'precision', 'recall']):\n",
        "        ax[i].plot(history.history[metric])\n",
        "        ax[i].plot(history.history['val_' + metric])\n",
        "        ax[i].set_title('Model {}'.format(metric))\n",
        "        ax[i].set_xlabel('Epochs')\n",
        "        ax[i].set_ylabel(metric.capitalize())\n",
        "        ax[i].legend(['Training', 'Validation'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvQgDuomrdvj"
      },
      "source": [
        "# Randomly pick and display an unseen image for the network to predict\n",
        "def select_testing_image():\n",
        "    image_num = random.randint(testing_set_start_index, testing_set_end_index)\n",
        "    testing_img = testing_generator[0][0][image_num]\n",
        "\n",
        "    class_num = np.argmax(testing_generator[0][1][image_num])\n",
        "    true_label = classes[class_num].capitalize()\n",
        "\n",
        "    print(f'True Label: {true_label}')\n",
        "\n",
        "    return testing_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5fkNRPnrhwg"
      },
      "source": [
        "# Run a diagnosis to determine if the patient is COVID-19 positive or negative\n",
        "def run_diagnosis(model, testing_img):      \n",
        "    img_array = img_to_array(testing_img)\n",
        "    img_array = img_array.reshape(-1, img_width, img_height, 3)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    class_num = predictions.argmax()\n",
        "\n",
        "    network_percent_confidence = str(np.max(predictions) * 100)[:4] + '% match'\n",
        "    network_prediction = classes[class_num].capitalize()\n",
        "\n",
        "    font = {'family': 'DejaVu Sans',\n",
        "            'color' : 'red',\n",
        "            'weight': 'heavy',\n",
        "            'size'  :  10}\n",
        "    \n",
        "    plt.imshow(testing_img)\n",
        "    # Find a way to only make the text after \"Network Prediction\" red\n",
        "    plt.title(f'Network Prediction: {network_prediction} ({network_percent_confidence})', fontdict=font) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZp15PKHz3EC"
      },
      "source": [
        "model = create_model()\n",
        "compile_model(model)\n",
        "print_model_summary(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CrhRgDDSVGX"
      },
      "source": [
        "history = fit_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUDvUoMpGP7f"
      },
      "source": [
        "evaluate_model(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjwace3Kf1cF"
      },
      "source": [
        "# Prints labels (alphabetical)\n",
        "training_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxFSVR9URG6p"
      },
      "source": [
        "def convert_to_img_array(img_path):\n",
        "    # img is a PIL image\n",
        "    img = load_img(img_path,\n",
        "                   target_size=target_size)\n",
        "    \n",
        "    # Convert to float32 Numpy array\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    # img_array = img_array.reshape((-1, img_width, img_height, 3))\n",
        "\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlIGXMgIX0oO"
      },
      "source": [
        "# ! pip install git+git://github.com/raghakot/keras-vis.git --upgrade --no-deps\n",
        "# import vis\n",
        "\n",
        "# from vis.utils import utils\n",
        "# from vis.visualization import visualize_cam\n",
        "\n",
        "# --------------------------------------------\n",
        "# FROM https://github.com/raghakot/keras-vis/blob/master/applications/self_driving/visualize_attention.ipynb\n",
        "# --------------------------------------------\n",
        "# for i, modifier in enumerate(modifiers):\n",
        "#     heatmap = visualize_cam(model, layer_idx=-1, filter_indices=0, \n",
        "#                             seed_input=bgr_img, grad_modifier=modifier)\n",
        "#     plt.figure()\n",
        "#     plt.title(titles[i])\n",
        "#     # Overlay is used to alpha blend heatmap onto img.\n",
        "#     jet_heatmap = np.uint8(cm.jet(heatmap)[..., :3] * 255)\n",
        "#     plt.imshow(overlay(img, jet_heatmap, alpha=0.7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0Csgu63RIf7"
      },
      "source": [
        "# classifier_layer_names = ['top_conv', 'top_bn', 'top_activation', 'global_average_pooling2d_1', 'dropout_1', 'dense_3', 'dense_4', 'dense_5']\n",
        "# last_conv_layer_name = 'block7d_add'\n",
        "\n",
        "# img_path = f'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_xray_dataset/Testing/covid19/Github COVID-19 X-ray Dataset/000001-1.jpg'\n",
        "\n",
        "# img = load_img(img_path,\n",
        "#                target_size=target_size)\n",
        "\n",
        "# img               = img_to_array(img)\n",
        "# # img               = preprocess_input(img)\n",
        "# y_pred            = model.predict(img[np.newaxis,...])\n",
        "# class_idxs_sorted = np.argsort(y_pred.flatten())[::-1]\n",
        "# # topNclass         = 5\n",
        "# # for i, idx in enumerate(class_idxs_sorted[:topNclass]):\n",
        "# #     print(\"Top {} predicted class:     Pr(Class={:18} [index={}])={:5.3f}\".format(\n",
        "# #           i + 1,classlabel[idx],idx,y_pred[0,idx]))\n",
        "\n",
        "# # Utility to search for layer index by name. \n",
        "# # ***********  Alternatively we can specify this as -1 since it corresponds to the last layer.  ***************\n",
        "# layer_idx = utils.find_layer_idx(model, 'dense_8')\n",
        "# # Swap softmax with linear\n",
        "# model.layers[layer_idx].activation = tf.keras.activations.linear\n",
        "# model = utils.apply_modifications(model)\n",
        "\n",
        "# penultimate_layer_idx = utils.find_layer_idx(model, \"top_conv\") \n",
        "# class_idx  = class_idxs_sorted[0]\n",
        "# seed_input = img\n",
        "# grad_top1  = visualize_cam(model, layer_idx, class_idx, seed_input, \n",
        "#                            penultimate_layer_idx = penultimate_layer_idx) # TRY TO LEAVE BLANK? -> OR AS 'none'?\n",
        "#                           #  backprop_modifier     = None)\n",
        "#                           #  grad_modifier         = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsSlDzFVRKUV"
      },
      "source": [
        "# def plot_map(grads):\n",
        "#     fig, axes = plt.subplots(1,2,figsize=(14,5))\n",
        "#     axes[0].imshow(_img)\n",
        "#     axes[1].imshow(_img)\n",
        "#     i = axes[1].imshow(grads,cmap=\"jet\", alpha=0.8)\n",
        "#     fig.colorbar(i)\n",
        "#     plt.suptitle(\"Pr(class={}) = {:5.2f}\".format(\n",
        "#                       classlabel[class_idx],\n",
        "#                       y_pred[0,class_idx]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35Ox0Yb3WrMB"
      },
      "source": [
        "testing_generator = testing_data_gen.flow_from_directory(ct_testing_dir,\n",
        "                                                         target_size = target_size,\n",
        "                                                         class_mode='binary',\n",
        "                                                         batch_size=batch_size,\n",
        "                                                         shuffle=False)\n",
        "\n",
        "print(testing_generator.labels)\n",
        "\n",
        "print(model.evaluate(testing_generator))\n",
        "\n",
        "predictions = model.predict(testing_generator)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPG_XkqLkZ-x"
      },
      "source": [
        "# # Test internet images (not reliable)\n",
        "# ct_testing_dir = f'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/Internet Images'\n",
        "\n",
        "# testing_generator = testing_data_gen.flow_from_directory(ct_testing_dir,\n",
        "#                                                          target_size = target_size,\n",
        "#                                                          class_mode='binary',\n",
        "#                                                          batch_size=batch_size,\n",
        "#                                                          shuffle=False)\n",
        "\n",
        "# print(testing_generator.labels)\n",
        "\n",
        "# predictions = model.predict(testing_generator)\n",
        "\n",
        "# i = 0;\n",
        "\n",
        "# font = {'family': 'DejaVu Sans',\n",
        "#             'color' : 'red',\n",
        "#             'weight': 'heavy',\n",
        "#             'size'  :  10}\n",
        "\n",
        "# for pred in predictions:\n",
        "#     print(str(i + 1) + \": \" + filepath)\n",
        "\n",
        "#     # Select the image array from the DirectoryIterator\n",
        "#     img_array = testing_generator[0][0][i]\n",
        "#     # Compress the array\n",
        "#     # img_array = img_array.reshape(1, img_width, img_height, 3)\n",
        "    \n",
        "#     true_label_class_index = testing_generator.labels[index]\n",
        "#     true_label = classes[true_label_class_index]\n",
        "\n",
        "#     # network_percent_confidence = str(np.max(pred) * 100)[:4] + '% match'\n",
        "    \n",
        "#     # Safe prediction for test positive\n",
        "#     # MAKE INTO CONSTANTS!!!!!!!!!!\n",
        "#     if pred > 0 and pred < 0.3:\n",
        "#         true_label_class_index = 0\n",
        "#         network_percent_confidence = str(((0.5 - pred) / 0.5) * PERCENTAGE_FACTOR)[1:5]\n",
        "#         print(network_percent_confidence)\n",
        "#         print()\n",
        "\n",
        "#     elif pred < 1 and pred > 0.7:\n",
        "#         true_label_class_index = 0\n",
        "#         network_percent_confidence = str(((pred - 0.5) / 0.5) * PERCENTAGE_FACTOR)[1:5]\n",
        "#         print(network_percent_confidence)\n",
        "#         print()\n",
        "\n",
        "#     else:\n",
        "#         # RETURN\n",
        "#         print(\"Uncertain\")\n",
        "#         print()\n",
        "    \n",
        "#     network_prediction = classes[true_label_class_index]\n",
        "    \n",
        "\n",
        "#     plt.imshow(img_array)\n",
        "\n",
        "#     print('True Label', true_label)\n",
        "#     print(pred)\n",
        "#     # print(f'Network Prediction: {network_prediction}')\n",
        "    \n",
        "#     # Find a way to only make the text after \"Network Prediction\" red\n",
        "#     plt.title(f'{network_prediction} ({network_percent_confidence} % match)', fontdict=font)\n",
        "\n",
        "#     i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGMH4U_dg4-R"
      },
      "source": [
        "# Test internet images (not reliable)\n",
        "ct_testing_dir = f'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/Internet Images'\n",
        "\n",
        "testing_generator = testing_data_gen.flow_from_directory(ct_testing_dir,\n",
        "                                                         target_size = target_size,\n",
        "                                                         class_mode='binary',\n",
        "                                                         batch_size=batch_size,\n",
        "                                                         shuffle=False)\n",
        "\n",
        "print(testing_generator.labels)\n",
        "\n",
        "font = {'family': 'DejaVu Sans',\n",
        "            'color' : 'red',\n",
        "            'weight': 'heavy',\n",
        "            'size'  :  10}\n",
        "\n",
        "# Loop thorough all the images stored in the DirectoryIterator\n",
        "for i in range(len(testing_generator[0][0])):\n",
        "    print(str(i + 1) + \": \" + testing_generator.filepaths[i])\n",
        "\n",
        "    # Select an image array\n",
        "    testing_image = testing_generator[0][0][i]\n",
        "    img_array = testing_image\n",
        "    \n",
        "    # Compress the array\n",
        "    img_array = img_array.reshape(1, img_width, img_height, 3)\n",
        "    \n",
        "    true_label_class_index = testing_generator.labels[i]\n",
        "    # true_label_class_index = testing_generator[0][1][i]\n",
        "    true_label = classes[true_label_class_index]\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    \n",
        "    # Safe prediction for test positive\n",
        "    # MAKE INTO CONSTANTS!!!!!!!!!!\n",
        "    if prediction > 0 and prediction < COVID_THRESHOLD:\n",
        "        network_percent_confidence = str(((EQUIDDST_MEAS - prediction) / EQUIDDST_MEAS) * PERCENTAGE_FACTOR)[1:5]\n",
        "        print(network_percent_confidence)\n",
        "        print()\n",
        "\n",
        "    elif prediction < 1 and prediction > NORMAL_THRESHOLD:\n",
        "        network_percent_confidence = str(((prediction - EQUIDDST_MEAS) / EQUIDDST_MEAS) * PERCENTAGE_FACTOR)[1:5]\n",
        "        print(network_percent_confidence)\n",
        "        print()\n",
        "\n",
        "    else:\n",
        "        # RETURN\n",
        "        print('Uncertain')\n",
        "        print()\n",
        "    \n",
        "    network_prediction = classes[true_label_class_index]\n",
        "  \n",
        "    print('True Label:', true_label)\n",
        "    print('Prediction:', prediction)\n",
        "    \n",
        "    plt.title(f'{network_prediction} ({network_percent_confidence} % match)', fontdict=font)\n",
        "    plt.imshow(img_array)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X2ExOPzXmyS"
      },
      "source": [
        "# print((testing_generator[0][0][-4]))\n",
        "# print(len(testing_generator[0][1]))\n",
        "\n",
        "# img_array = img_to_array(testing_generator[0][0][0])\n",
        "img_array = testing_generator[0][0][0].reshape(1, img_width, img_height, 3)\n",
        "\n",
        "# print(len(img_array))\n",
        "# print(testing_generator[0][0])\n",
        "index_num = 1\n",
        "\n",
        "# for val in testing_generator.__getitem__(0):\n",
        "#     print(str(index_num) + ': ' + str(val))\n",
        "#     index_num += 1\n",
        "\n",
        "# for val in testing_generator[0][0][0]:\n",
        "#     print(str(index_num) + ': ' + str(val))\n",
        "#     index_num += 1\n",
        "\n",
        "print(type(testing_generator.filepaths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIYd7leVp526"
      },
      "source": [
        "GRAD-Cam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjqaPR0NSXYO"
      },
      "source": [
        "# img_path = f'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_xray_dataset/Testing/covid19/Github COVID-19 X-ray Dataset/000001-1.jpg'\n",
        "# plot_map(grad_top1)\n",
        "\n",
        "# Upload files to test\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for filename in uploaded.keys():\n",
        "#     # print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#     #     name=filename, length=len(uploaded[filename])))\n",
        "\n",
        "#     img_path = filename\n",
        "#     img = load_img(img_path,\n",
        "#                    target_size=target_size)\n",
        "#     img_array = img_to_array(img)\n",
        "#     img_array = np.expand_dims(img_array, axis=0)\n",
        "#     print(img_array)\n",
        "\n",
        "    # testing_images = np.vstack([img_array])\n",
        "    # predictions = model.predict(testing_generator)\n",
        "    # class_pred = predictions.argmax(axis=-1)\n",
        "    # print(predictions)\n",
        "    # print(class_pred)\n",
        "\n",
        "# testing_img = select_testing_image()\n",
        "# run_diagnosis(model, testing_img)\n",
        "# # From COVIDNet-CT: https://github.com/haydengunraj/COVIDNet-CT/blob/master/run_covidnet_ct.py\n",
        "# print('**DISCLAIMER**')\n",
        "#             print('Do not use this prediction for self-diagnosis. '\n",
        "#                   'You should check with your local authorities for '\n",
        "#                   'the latest advice on seeking medical assistance.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD2_uD24jpXM"
      },
      "source": [
        "# #@title Enter Filepath Here:\n",
        "# filename = \"/content/chest_xray/val/PNEUMONIA/person1946_bacteria_4874.jpeg\" #@param {type:\"string\"}\n",
        "\n",
        "# img = image.load_img(filename, \n",
        "#                      target_size=(150, 150))\n",
        "# x = image.img_to_array(img)\n",
        "# x = np.expand_dims(x, axis=0)\n",
        "# x = preprocess_input(x)\n",
        "\n",
        "# y = final_model.predict(x)\n",
        "\n",
        "# predicton=\"Normal\" if y.argmax(axis=-1)==0 else \"Pneumonia\"\n",
        "# actual=\"Normal\" if \"NORMAL\" in filename else \"Pneumonia\" \n",
        "\n",
        "# img=mpimg.imread(filename)\n",
        "# title_text = (\"%s%s%s%s%s\"%(\"True Label: \", actual, \"\\n\", \"Prediction: \", predicton))\n",
        "# plt.title(title_text)\n",
        "# imgplot=plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}