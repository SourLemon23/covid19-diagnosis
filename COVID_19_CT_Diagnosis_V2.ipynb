{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID-19 CT Diagnosis V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SourLemon23/covid19-diagnosis/blob/master/COVID_19_CT_Diagnosis_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgT4IENiWErj"
      },
      "source": [
        "# ! pip install keras==2.2.0\n",
        "# ! pip install tensorflow==1.10.0\n",
        "# ! pip install keras==2.2.2 # EfficientNet PyPi\n",
        "# ! pip install tensorflow==1.12.0 # EfficientNet PyPi\n",
        "\n",
        "# Versions that are compatible with vis\n",
        "# ! pip install keras==2.2.4\n",
        "# ! pip install tensorflow==1.14.0\n",
        "# ! pip install keras_applications >= 1.0.7\n",
        "# https://stackoverflow.com/questions/57773636/no-attribute-set-keras-submodules\n",
        "\n",
        "# ! pip install vis\n",
        "# ! pip install scipy==1.1.0"
      ],
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjjOAtntgVOi",
        "outputId": "feeecd72-80c1-4277-9492-a9660aaa4d71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass\n",
        "\n",
        "print('Using TensorFlow Version:', tf.__version__)\n",
        "\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, MaxPooling2D, BatchNormalization, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# EfficientNetB7\n",
        "! pip install -U efficientnet\n",
        "from efficientnet.tfkeras import EfficientNetB7\n",
        "\n",
        "# Grad-CAM\n",
        "import scipy\n",
        "print('Using SciPy Version:', scipy.__version__) # Should be 1.1.0"
      ],
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow Version: 2.3.0\n",
            "Requirement already up-to-date: efficientnet in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.5)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\n",
            "Using SciPy Version: 1.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlIGXMgIX0oO"
      },
      "source": [
        "# ! pip install git+git://github.com/raghakot/keras-vis.git --upgrade --no-deps\n",
        "# import vis\n",
        "\n",
        "# from vis.utils import utils\n",
        "# from vis.visualization import visualize_cam\n",
        "\n",
        "# --------------------------------------------\n",
        "# FROM https://github.com/raghakot/keras-vis/blob/master/applications/self_driving/visualize_attention.ipynb\n",
        "# --------------------------------------------\n",
        "# for i, modifier in enumerate(modifiers):\n",
        "#     heatmap = visualize_cam(model, layer_idx=-1, filter_indices=0, \n",
        "#                             seed_input=bgr_img, grad_modifier=modifier)\n",
        "#     plt.figure()\n",
        "#     plt.title(titles[i])\n",
        "#     # Overlay is used to alpha blend heatmap onto img.\n",
        "#     jet_heatmap = np.uint8(cm.jet(heatmap)[..., :3] * 255)\n",
        "#     plt.imshow(overlay(img, jet_heatmap, alpha=0.7))"
      ],
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6kecoNB96D_",
        "outputId": "4bfc56fe-bd07-4d41-f1ba-73d57976715b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Authorize access to mount Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCHnggpYLkhj"
      },
      "source": [
        "# # Upload files\n",
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqhZS-bor5Kj"
      },
      "source": [
        "# Initialize dataset directories (Google Drive)\n",
        "# ct_training_dir   = r'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_ct_dataset/Training'\n",
        "# ct_validation_dir = r'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_ct_dataset/Validation'\n",
        "# ct_testing_dir    = r'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_ct_dataset/Testing'\n",
        "\n",
        "ct_training_dir   = r'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_ct_dataset - Copy/Training'\n",
        "ct_validation_dir = r'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_ct_dataset - Copy/Validation'\n",
        "ct_testing_dir    = r'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_ct_dataset - Copy/Testing'"
      ],
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMGd2ZQ-Ajwq"
      },
      "source": [
        "# # Store all testing images in a randomized list\n",
        "# testing_img_paths = []\n",
        "\n",
        "# for root, dirs, files in os.walk(testing_dir):\n",
        "#     for filename in files:\n",
        "#         testing_img_paths.append(os.path.abspath(os.path.join(root, filename)))\n",
        "\n",
        "# # Randomize the list\n",
        "# random.shuffle(testing_img_paths)"
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVdTndo2sEa_"
      },
      "source": [
        "# Initialize constants\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Make sure to make these all CAPS\n",
        "# ---------------------------------------------------------\n",
        "classes = ['COVID-19 Positive', 'COVID-19 Negative']\n",
        "img_width, img_height = 150, 150\n",
        "target_size = (img_width, img_height)\n",
        "input_shape = (img_width, img_height, 3)\n",
        "\n",
        "testing_set_start_index = -50\n",
        "testing_set_end_index = 49\n",
        "\n",
        "batch_size = 30\n",
        "epochs = 10\n",
        "dropout_rate = 0.2\n",
        "metrics = [BinaryAccuracy(name='binary_accuracy'),\n",
        "           Precision(name='precision'),\n",
        "           Recall(name='recall')]"
      ],
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJKmCSqIqFDe"
      },
      "source": [
        "# Augment data\n",
        "training_data_gen = ImageDataGenerator(rescale=1./255,\n",
        "                                       featurewise_center=False, # Set input mean to 0 over dataset\n",
        "                                       samplewise_center=False, # Set each sample mean to 0\n",
        "                                       featurewise_std_normalization=False, # Divide inputs by std of dataset\n",
        "                                       samplewise_std_normalization=False, # Divide each input by its std\n",
        "                                       horizontal_flip=True,\n",
        "                                       vertical_flip=True,\n",
        "                                       zoom_range=0.15,\n",
        "                                       shear_range=0.15,\n",
        "                                       rotation_range=360,\n",
        "                                       width_shift_range=0.15,\n",
        "                                       height_shift_range=0.15,\n",
        "                                       validation_split=0.15)\n",
        "\n",
        "validation_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "testing_data_gen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yL5qRmWqJ_t",
        "outputId": "4b4f1dee-ae40-4056-cfb6-0935ca6053a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Split data\n",
        "training_generator = training_data_gen.flow_from_directory(ct_training_dir,\n",
        "                                                           target_size=target_size,\n",
        "                                                           class_mode='binary',\n",
        "                                                           batch_size=batch_size,\n",
        "                                                           shuffle=True)\n",
        "\n",
        "#  SHUFFLE = TRUE??\n",
        "validation_generator = validation_data_gen.flow_from_directory(ct_validation_dir,\n",
        "                                                               target_size=target_size,\n",
        "                                                               class_mode='binary',\n",
        "                                                               batch_size=batch_size,\n",
        "                                                               shuffle=False)\n",
        "\n",
        "testing_generator = testing_data_gen.flow_from_directory(ct_testing_dir,\n",
        "                                                         target_size = target_size,\n",
        "                                                         class_mode='binary',\n",
        "                                                         batch_size=batch_size,\n",
        "                                                         shuffle=True)"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4015 images belonging to 2 classes.\n",
            "Found 348 images belonging to 2 classes.\n",
            "Found 390 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFq_ad5r55J7"
      },
      "source": [
        "# from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "\n",
        "# def build_model(num_classes):\n",
        "#     inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "#     x = img_augmentation(inputs)\n",
        "#     model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
        "\n",
        "#     # Freeze the pretrained weights\n",
        "#     model.trainable = False\n",
        "\n",
        "#     # Rebuild top\n",
        "#     x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "\n",
        "#     top_dropout_rate = 0.2\n",
        "#     x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "#     outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "#     # Compile\n",
        "#     model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "#     optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "#     model.compile(\n",
        "#         optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "#     )\n",
        "#     return model"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Koy33zgrnfHR"
      },
      "source": [
        "# Create a neural network\n",
        "def create_model():\n",
        "    # Instantiate a base model with pre-trained weights.\n",
        "    base_model = EfficientNetB7(weights='imagenet',include_top=False, pooling=\"max\", input_shape=input_shape)\n",
        "    # Freeze the base model\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    input = Input(shape=input_shape)\n",
        "    x = base_model(input, training=False)\n",
        "    # x = model.output\n",
        "\n",
        "    # Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "    # x = MaxPooling2D()(x) # Max pooling picks up more prominent, sharp features than average pooling\n",
        "    # x = keras.layers.GlobalAveragePooling2D()(x)    \n",
        "\n",
        "    # A Dense classifier with a single unit (binary classification)\n",
        "    # predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "    predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=input, outputs=predictions)\n",
        "\n",
        "    # x = model.output\n",
        "    # x = Conv2D(16, (3, 3), activation = 'relu', padding='same', input_shape=input_shape)(x)\n",
        "    # x = MaxPooling2D(pool_size=(2, 2), padding='same')(x) # Max pooling picks up more prominent, sharp features than average pooling\n",
        "    # # x = BatchNormalization()(x)\n",
        "    # x = Dropout(0.5)(x)\n",
        "\n",
        "    # x = Flatten()(x)\n",
        "\n",
        "    # x = Dense(16, activation=\"relu\")(x)\n",
        "    # x = Dense(8,  activation=\"relu\")(x)\n",
        "    # x = Dense(training_generator.num_classes, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW7Xtc4g8-si"
      },
      "source": [
        "def conv_block(x, filters):\n",
        "    x = Conv2D(filters, (3, 3), activation = 'relu', padding='same', input_shape=input_shape)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x) # Max pooling picks up more prominent, sharp features than average pooling\n",
        "    x = Dropout(dropout_rate)(x)"
      ],
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVRJf8sO9CX4"
      },
      "source": [
        "def dense_block(x, units):\n",
        "    x = Dense(units, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)"
      ],
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY5a_IOvhEBm"
      },
      "source": [
        "# Create a neural network\n",
        "def create_model():\n",
        "    # Instantiate a base model with pre-trained weights.\n",
        "    base_model = EfficientNetB7(weights='imagenet',\n",
        "                                include_top=False,\n",
        "                                input_shape=input_shape)\n",
        "    # Freeze the base model\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    input = Input(shape=input_shape)\n",
        "    x = base_model(input,\n",
        "                   training=True)\n",
        "\n",
        "    conv_block(x, 16)\n",
        "    conv_block(x, 32)\n",
        "    conv_block(x, 64)\n",
        "\n",
        "    dense_block(x, 16)\n",
        "    dense_block(x, 32)\n",
        "    dense_block(x, 64)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # A Dense classifier with a single unit (binary classification)\n",
        "    predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=input, outputs=predictions)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAjH_v2nrX-d"
      },
      "source": [
        "# Print a summary of the network architecture\n",
        "def print_model_summary(model):\n",
        "    model.summary()"
      ],
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq1iB5fEraE-"
      },
      "source": [
        "# Configure model\n",
        "def compile_model(model):\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam', # tf.keras.optimizers.RMSprop(lr=1e-4)\n",
        "                  metrics=metrics)"
      ],
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjaNqpx9rdcb"
      },
      "source": [
        "# Train the model\n",
        "def fit_model(model):\n",
        "    # Early Stopping Implementation from: https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_03_4_early_stop.ipynb\n",
        "    # Early Stopping Documentation: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
        "    # es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "    #                                           min_delta=1e-3,\n",
        "    #                                           patience=3,\n",
        "    #                                           verbose=1,\n",
        "    #                                           mode='auto')\n",
        "\n",
        "    history = model.fit(training_generator,\n",
        "                        epochs=epochs,\n",
        "                        steps_per_epoch=(training_generator.n/batch_size),\n",
        "                        validation_data=validation_generator,\n",
        "                        validation_steps=(validation_generator.n/batch_size))\n",
        "                        # callbacks=[es_callback])\n",
        "    \n",
        "    return history"
      ],
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhAtKxg8rfqI"
      },
      "source": [
        "# Evaluate the model\n",
        "def evaluate_model(history):\n",
        "    acc = history.history['binary_accuracy']\n",
        "    val_acc = history.history['val_binary_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(epochs)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')"
      ],
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvQgDuomrdvj"
      },
      "source": [
        "# Randomly pick and display an unseen image for the network to predict\n",
        "def select_testing_image():\n",
        "    image_num = random.randint(testing_set_start_index, testing_set_end_index)\n",
        "    testing_img = testing_generator[0][0][image_num]\n",
        "\n",
        "    class_num = np.argmax(testing_generator[0][1][image_num])\n",
        "    true_label = classes[class_num].capitalize()\n",
        "\n",
        "    print(f'True Label: {true_label}')\n",
        "\n",
        "    return testing_img"
      ],
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5fkNRPnrhwg"
      },
      "source": [
        "# Run a diagnosis to determine if the patient is COVID-19 positive or negative\n",
        "def run_diagnosis(model, testing_img):      \n",
        "    img_array = img_to_array(testing_img)\n",
        "    img_array = img_array.reshape(-1, img_width, img_height, 3)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    class_num = predictions.argmax()\n",
        "\n",
        "    network_percent_confidence = str(np.max(predictions) * 100)[:4] + '% match'\n",
        "    network_prediction = classes[class_num].capitalize()\n",
        "\n",
        "    font = {'family': 'DejaVu Sans',\n",
        "            'color' : 'red',\n",
        "            'weight': 'heavy',\n",
        "            'size'  :  10}\n",
        "    \n",
        "    plt.imshow(testing_img)\n",
        "    # Find a way to only make the text after \"Network Prediction\" red\n",
        "    plt.title(f'Network Prediction: {network_prediction} ({network_percent_confidence})', fontdict=font) "
      ],
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZp15PKHz3EC",
        "outputId": "6e334b03-344f-485e-fc54-4c8c014f674d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = create_model()\n",
        "compile_model(model)\n",
        "print_model_summary(model)"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_29 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "efficientnet-b7 (Functional) (None, 5, 5, 2560)        64097680  \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 64000)             0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1)                 64001     \n",
            "=================================================================\n",
            "Total params: 64,161,681\n",
            "Trainable params: 64,001\n",
            "Non-trainable params: 64,097,680\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CrhRgDDSVGX",
        "outputId": "410d1eef-3384-45c9-c7ea-5bbd59959ea4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = fit_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "134/133 [==============================] - 936s 7s/step - loss: 0.5626 - binary_accuracy: 0.8090 - precision: 0.8155 - recall: 0.8182 - val_loss: 1.7286 - val_binary_accuracy: 0.6149 - val_precision: 0.6052 - val_recall: 0.9397\n",
            "Epoch 2/10\n",
            "134/133 [==============================] - 925s 7s/step - loss: 0.3928 - binary_accuracy: 0.8700 - precision: 0.8758 - recall: 0.8742 - val_loss: 2.1131 - val_binary_accuracy: 0.6063 - val_precision: 0.6092 - val_recall: 0.8693\n",
            "Epoch 3/10\n",
            "134/133 [==============================] - 946s 7s/step - loss: 0.3036 - binary_accuracy: 0.9021 - precision: 0.9077 - recall: 0.9038 - val_loss: 2.0294 - val_binary_accuracy: 0.6264 - val_precision: 0.6547 - val_recall: 0.7337\n",
            "Epoch 4/10\n",
            "134/133 [==============================] - 973s 7s/step - loss: 0.2779 - binary_accuracy: 0.9188 - precision: 0.9244 - recall: 0.9191 - val_loss: 2.7319 - val_binary_accuracy: 0.6437 - val_precision: 0.6298 - val_recall: 0.9146\n",
            "Epoch 5/10\n",
            "134/133 [==============================] - 914s 7s/step - loss: 0.3072 - binary_accuracy: 0.9123 - precision: 0.9166 - recall: 0.9148 - val_loss: 2.7959 - val_binary_accuracy: 0.6351 - val_precision: 0.6224 - val_recall: 0.9196\n",
            "Epoch 6/10\n",
            "134/133 [==============================] - ETA: -1s - loss: 0.2857 - binary_accuracy: 0.9235 - precision: 0.9268 - recall: 0.9263"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUDvUoMpGP7f"
      },
      "source": [
        "evaluate_model(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxFSVR9URG6p"
      },
      "source": [
        "classifier_layer_names = ['top_conv', 'top_bn', 'top_activation', 'global_average_pooling2d_1', 'dropout_1', 'dense_3', 'dense_4', 'dense_5']\n",
        "last_conv_layer_name = 'block7d_add'\n",
        "\n",
        "def convert_to_img_array(img_path):\n",
        "    # img is a PIL image\n",
        "    img = load_img(img_path,\n",
        "                   target_size=target_size)\n",
        "    \n",
        "    # Convert to float32 Numpy array\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    # img_array = img_array.reshape((-1, img_width, img_height, 3))\n",
        "\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0Csgu63RIf7"
      },
      "source": [
        "# classifier_layer_names = ['top_conv', 'top_bn', 'top_activation', 'global_average_pooling2d_1', 'dropout_1', 'dense_3', 'dense_4', 'dense_5']\n",
        "# last_conv_layer_name = 'block7d_add'\n",
        "\n",
        "# img_path = f'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_xray_dataset/Testing/covid19/Github COVID-19 X-ray Dataset/000001-1.jpg'\n",
        "\n",
        "# img = load_img(img_path,\n",
        "#                target_size=target_size)\n",
        "\n",
        "# img               = img_to_array(img)\n",
        "# # img               = preprocess_input(img)\n",
        "# y_pred            = model.predict(img[np.newaxis,...])\n",
        "# class_idxs_sorted = np.argsort(y_pred.flatten())[::-1]\n",
        "# # topNclass         = 5\n",
        "# # for i, idx in enumerate(class_idxs_sorted[:topNclass]):\n",
        "# #     print(\"Top {} predicted class:     Pr(Class={:18} [index={}])={:5.3f}\".format(\n",
        "# #           i + 1,classlabel[idx],idx,y_pred[0,idx]))\n",
        "\n",
        "# # Utility to search for layer index by name. \n",
        "# # ***********  Alternatively we can specify this as -1 since it corresponds to the last layer.  ***************\n",
        "# layer_idx = utils.find_layer_idx(model, 'dense_8')\n",
        "# # Swap softmax with linear\n",
        "# model.layers[layer_idx].activation = tf.keras.activations.linear\n",
        "# model = utils.apply_modifications(model)\n",
        "\n",
        "# penultimate_layer_idx = utils.find_layer_idx(model, \"top_conv\") \n",
        "# class_idx  = class_idxs_sorted[0]\n",
        "# seed_input = img\n",
        "# grad_top1  = visualize_cam(model, layer_idx, class_idx, seed_input, \n",
        "#                            penultimate_layer_idx = penultimate_layer_idx) # TRY TO LEAVE BLANK? -> OR AS 'none'?\n",
        "#                           #  backprop_modifier     = None)\n",
        "#                           #  grad_modifier         = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsSlDzFVRKUV"
      },
      "source": [
        "# def plot_map(grads):\n",
        "#     fig, axes = plt.subplots(1,2,figsize=(14,5))\n",
        "#     axes[0].imshow(_img)\n",
        "#     axes[1].imshow(_img)\n",
        "#     i = axes[1].imshow(grads,cmap=\"jet\", alpha=0.8)\n",
        "#     fig.colorbar(i)\n",
        "#     plt.suptitle(\"Pr(class={}) = {:5.2f}\".format(\n",
        "#                       classlabel[class_idx],\n",
        "#                       y_pred[0,class_idx]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjqaPR0NSXYO"
      },
      "source": [
        "# img_path = f'/content/drive/My Drive/Colab Notebooks/COVID-19 Diagnosis/covid19_xray_dataset/Testing/covid19/Github COVID-19 X-ray Dataset/000001-1.jpg'\n",
        "# plot_map(grad_top1)\n",
        "\n",
        "# testing_img = select_testing_image()\n",
        "# run_diagnosis(model, testing_img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}